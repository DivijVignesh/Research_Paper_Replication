# Research Paper Replication

## Overview
The main objective of these 2 research paper replication was to understand the research implementation process and also to verify the credibility of the research paper.
These research papers have a lot of information regarding transfer learning concepts. Understanding and implementing the research methodologies had improved my understanding
about these critical transfer learning concepts.

## Files
Each of the folders have the following below paper implementation. Along with the train.py files there is also a report about the replication in each sub folder. 
These reports consists of result comparision with the original paper results and the replication results.

### **Paper 1: Vision Transformer/CNN Block Analysis**  
*Investigating Transfer Learning Capabilities of Vision Transformers and CNNs by Fine-Tuning a Single Trainable Block*  
**Focus**:  
- Comparative transfer learning efficiency between ViTs and CNNs  
- Single-block fine-tuning paradigm analysis  
- Architectural alignment challenges in vision models  

### **Paper 2: DistilBERT Knowledge Distillation**  
*DistilBERT: Smaller, Faster, Cheaper and Lighter*  
**Focus**:  
- Language model compression via distillation  
- Cross-architecture knowledge transfer  
- Resource-efficient NLP deployment  



